{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Object `dirlist` not found.\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pkl_file = open('trained_classifier_test.p', 'rb')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data1 = pickle.load(pkl_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print data1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RandomForestClassifier(bootstrap=True, compute_importances=True,\n",
        "            criterion=gini, max_depth=None, max_features=auto,\n",
        "            min_density=0.1, min_samples_leaf=1, min_samples_split=2,\n",
        "            n_estimators=50, n_jobs=-1, oob_score=False, random_state=None,\n",
        "            verbose=0)\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run_final_classifier(path, clf_path):\n",
      "    # import\n",
      "#!/usr/bin/env python\n",
      "    import matplotlib.pyplot as plt\n",
      "    from glob import glob\n",
      "    import numpy as np\n",
      "    import scipy.ndimage as ndimg\n",
      "    import skimage.filter as filter\n",
      "    import skimage.transform as transform\n",
      "    import re\n",
      "    from os import listdir\n",
      "    from multiprocessing import Pool, cpu_count\n",
      "    from pylab import imread\n",
      "    from time import time\n",
      "    import pickle\n",
      "    from sklearn.ensemble import RandomForestClassifier\n",
      "    \n",
      "    def row(img2d):\n",
      "        return np.shape(img2d)[0]\n",
      "        \n",
      "    def col(img2d):\n",
      "        return np.shape(img2d)[1]\n",
      "    \n",
      "    def layer_mean(img2d):\n",
      "        img1d = img2d[img2d<255]\n",
      "        return img1d.mean()\n",
      "    \n",
      "    def hist_max(img2d):\n",
      "        img1d = img2d[img2d<255]\n",
      "        [n, bins, patches]= plt.hist(img1d, np.arange(255))\n",
      "        return bins[n.argmax()]\n",
      "    \n",
      "    def edge_length(img2d):\n",
      "        \"gray input\"\n",
      "        imgsize = float((img2d.shape[0]*img2d.shape[1]))\n",
      "        med_filter = ndimg.median_filter(img2d, size = (5,5))\n",
      "        edges = filter.canny(med_filter,3)\n",
      "        return edges.sum()/imgsize\n",
      "    \n",
      "    def edge_sobel_h(img2d):\n",
      "        \"gray input\"\n",
      "        imgsize = float((img2d.shape[0]*img2d.shape[1]))\n",
      "        med_filter = ndimg.median_filter(img2d, size = (5,5))\n",
      "        edges_h = filter.hsobel(med_filter/255.)\n",
      "        return edges_h.sum()/imgsize\n",
      "    \n",
      "    def edge_sobel_v(img2d):\n",
      "        \"gray input\"\n",
      "        imgsize = float((img2d.shape[0]*img2d.shape[1]))\n",
      "        med_filter = ndimg.median_filter(img2d, size = (5,5))\n",
      "        edges_v = filter.vsobel(med_filter/255.)\n",
      "        return edges_v.sum()/imgsize\n",
      "    \n",
      "    def edge_sobel(img2d):\n",
      "        \"gray input\"\n",
      "        imgsize = float((img2d.shape[0]*img2d.shape[1]))\n",
      "        med_filter = ndimg.median_filter(img2d, size = (5,5))\n",
      "        edges = filter.sobel(med_filter/255.)\n",
      "        return edges.sum()/imgsize\n",
      "    \n",
      "    def houghLine(img2d):\n",
      "        \"gray input\"\n",
      "        med_filter = ndimg.median_filter(img2d, size = (5,5))\n",
      "        edges = filter.sobel(med_filter/255.)\n",
      "        [H,theta,distances] = transform.hough_line(edges);\n",
      "        imgsize = float(len(theta)*len(distances))\n",
      "        return H.sum()/imgsize\n",
      "    \n",
      "#    def cate_extract(image_path):\n",
      "#        cate_temp = image_path.replace(MYDIRECTORY,'')\n",
      "#        cate = re.search(r'/.+?/', cate_temp)\n",
      "#        return cate_map[cate.group()[1:-1]]\n",
      "    \n",
      "    def features(image_path):\n",
      "        #red mean\n",
      "        img2d = ndimg.imread(image_path)\n",
      "        img2d_gray = ndimg.imread(image_path, flatten= True)\n",
      "        \n",
      "        row_n = row(img2d_gray)\n",
      "        col_n = col(img2d_gray)\n",
      "        \n",
      "        red_mean = layer_mean(img2d[...,0])\n",
      "        green_mean = layer_mean(img2d[...,1])\n",
      "        blue_mean = layer_mean(img2d[...,2])\n",
      "        gray_mean = layer_mean(img2d_gray)\n",
      "        \n",
      "        red_most = hist_max(img2d[...,0])\n",
      "        green_most = hist_max(img2d[...,1])\n",
      "        blue_most = hist_max(img2d[...,2])\n",
      "        gray_most = hist_max(img2d_gray)\n",
      "        \n",
      "        length = edge_length(img2d_gray)\n",
      "        sobel_h = edge_sobel_h(img2d_gray)\n",
      "        sobel_v = edge_sobel_v(img2d_gray)\n",
      "        sobel = edge_sobel(img2d_gray)\n",
      "        hough = houghLine(img2d_gray)\n",
      "        \n",
      "#        cate = cate_extract(image_path)\n",
      "        \n",
      "        return list([row_n, col_n, red_mean, green_mean, blue_mean, gray_mean,\\\n",
      "                         red_most,green_most,blue_most, gray_most,\\\n",
      "                         length, sobel_h, sobel_v, sobel, hough])\n",
      "        \n",
      "    #!/usr/bin/env python\n",
      "    \"\"\"\n",
      "    AY 250 - Scientific Research Computing with Python\n",
      "    Homework Assignment 4 - Parallel Feature Extraction Example\n",
      "    Author: Christopher Klein, Joshua Bloom\n",
      "    \"\"\"\n",
      "    ## CHANGE THIS NEXT LINE!\n",
      "    MYDIRECTORY = path\n",
      "    \n",
      "    # FUNCTION DEFINITIONS\n",
      "    # Quick function to divide up a large list into multiple small lists, \n",
      "    # attempting to keep them all the same size. \n",
      "    def split_seq(seq, size):\n",
      "            newseq = []\n",
      "            splitsize = 1.0/size*len(seq)\n",
      "            for i in range(size):\n",
      "                newseq.append(seq[int(round(i*splitsize)):\n",
      "                    int(round((i+1)*splitsize))])\n",
      "            return newseq\n",
      "    # Our simple feature extraction function. It takes in a list of image paths, \n",
      "    # does some measurement on each image, then returns a list of the image paths\n",
      "    # paired with the results of the feature measurement.\n",
      "    def extract_features(image_path_list):\n",
      "        feature_list = []\n",
      "        for image_path in image_path_list:\n",
      "            image_array = imread(image_path)\n",
      "            ft = features(image_path)\n",
      "            \n",
      "            #ft = image_array.shape # This feature is simple. You can modify this\n",
      "            # code to produce more complicated features and to produce multiple\n",
      "            # features in one function call.\n",
      "            feature_list.append(ft)\n",
      "        return feature_list\n",
      "    ### Main program starts here ###################################################\n",
      "    # We first collect all the local paths to all the images in one list\n",
      "    image_paths = []\n",
      "    imgsList = listdir(MYDIRECTORY)\n",
      "    \n",
      "    \n",
      "    for name in imgsList:\n",
      "        image_paths.append(MYDIRECTORY+'/'+name)\n",
      "    \n",
      "    print 'filename' + 15*' '+ 'predicted_class'\n",
      "    print '_ '*20\n",
      "    # Then, we run the feature extraction function using multiprocessing.Pool so \n",
      "    # so that we can parallelize the process and run it much faster.\n",
      "    #numprocessors = cpu_count() # To see results of parallelizing, set numprocessors\n",
      "    # to less than cpu_count().\n",
      "    \n",
      "    #create an array to store features\n",
      "    #nFeature = 13\n",
      "    #features_array = np.zeros(len(image_paths), nFeature)\n",
      "    \n",
      "    numprocessors = 1\n",
      "    \n",
      "    # We have to cut up the image_paths list into the number of processes we want to\n",
      "    # run. \n",
      "    split_image_paths = split_seq(image_paths, numprocessors)\n",
      "    \n",
      "    # Ok, this block is where the parallel code runs. We time it so we can get a \n",
      "    # feel for the speed up.\n",
      "    start_time = time()\n",
      "    p = Pool(numprocessors)\n",
      "    result = p.map_async(extract_features, split_image_paths)\n",
      "    poolresult = result.get()\n",
      "    end_time = time()\n",
      "    #DATA = np.vstack([poolresult[i] for i in range(np.shape(poolresult)[0])])\n",
      "    # All done, print timing results.\n",
      "    print (\"Finished extracting features. Total time: \" + \n",
      "        str(round(end_time-start_time, 3)) + \" s, or \" + \n",
      "        str( round( (end_time-start_time)/len(image_paths), 5 ) ) + \" s/image.\")\n",
      "    # This took about 10-11 seconds on my 2.2 GHz, Core i7 MacBook Pro. It may also\n",
      "    # be affected by hard disk read speeds.\n",
      "    \n",
      "    # To tidy-up a bit, we loop through the poolresult to create a final list of\n",
      "    # the feature extraction results for all images.\n",
      "    combined_result = []\n",
      "    for single_proc_result in poolresult:\n",
      "        for single_image_result in single_proc_result:\n",
      "            combined_result.append(single_image_result)\n",
      "    X_test = np.array(combined_result)\n",
      "    \n",
      "    clf = pickle.load(open(clf_path, 'rb'))\n",
      "    categories = pickle.load(open('categories.p', 'rb'))\n",
      "    cate_map = dict(zip(range(len(categories)),categories))\n",
      "\n",
      "    Y_pred_num = clf.predict(X_test)\n",
      "    for i in len(Y_pred_num):\n",
      "        filename = image_paths[i].replace(path,'')\n",
      "        print filename[1:]+ ' '*10 + cate_map[Y_pred_num[i]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path = '/home/yigong/Documents/Class/AY250/hw4/classifier/airplanes'\n",
      "clf_path = '/home/yigong/Documents/Class/AY250/hw4/trained_classifier.p'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    import matplotlib.pyplot as plt\n",
      "    from glob import glob\n",
      "    import numpy as np\n",
      "    import scipy.ndimage as ndimg\n",
      "    import skimage.filter as filter\n",
      "    import skimage.transform as transform\n",
      "    import re\n",
      "    from os import listdir\n",
      "    from multiprocessing import Pool, cpu_count\n",
      "    from pylab import imread\n",
      "    from time import time\n",
      "    import pickle\n",
      "    from sklearn.ensemble import RandomForestClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "run_final_classifier(path, clf_path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "filename               predicted_class\n",
        "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "listdir(path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "['airplanes_0002.jpg',\n",
        " 'airplanes_0003.jpg',\n",
        " 'airplanes_0001.jpg',\n",
        " 'airplanes_0004.jpg',\n",
        " 'airplanes_0005.jpg']"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from os import listdir"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "categories = listdir(dirrr)[1:]\n",
      "pickle.dump(categories, open('categories.p','w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "categories = pickle.load(open('categories.p', 'rb'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cate_map = dict(zip(range(len(categories)),categories))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in len()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyError",
       "evalue": "'0'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-29-3927af6bc1c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcate_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mKeyError\u001b[0m: '0'"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cate_map[np.array([1,2,3])]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "unhashable type: 'numpy.ndarray'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-34-973c34e3f408>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcate_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filename = '/adsf'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print filename[1:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "adsf\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imag"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}